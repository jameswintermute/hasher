# NAS File Hasher & Duplicate Finder

Robust hashing + duplicate discovery + safe cleanup tooling for NAS environments (Synology DSM friendly).

> **Safetyâ€‘first design:** everything is a *candidate at scan time* until reâ€‘verified right before action.  
> Deletions require an explicit `--force`; most flows support quarantine.

---

## ğŸš€ Quickstart (recommended)

```bash
# Clone the repo
git clone https://github.com/yourusername/hasher.git
cd hasher

# Make scripts executable
chmod +x launcher.sh
chmod +x bin/*.sh

# Add the directories you want to scan (one per line)
nano local/paths.txt

# Launch (menu-driven)
./launcher.sh
```

**Notes**
- The launcher is menuâ€‘driven; no flags on the launcher itself.
- To run hashing directly, use: `bin/hasher.sh --pathfile local/paths.txt`.
- **Stage 2** of the launcher: run **duplicate folders** before **duplicate files** for fastest wins.

---

## â„¹ï¸ About

A project by **James Wintermute**.  
Originally started **Dec 2022**, significantly upgraded in **2025**.

---

## ğŸ¯ Purpose

Hasher helps protect NASâ€‘stored data by:

- Generating cryptographic hashes (sha256 default)
- Detecting silent corruption or damage (e.g., ransomware, bitrot)
- Supporting backup rotation validation
- Feeding SIEM or monitoring systems
- Finding **duplicate folders** (exact treeâ€‘level duplicates)
- Finding **duplicate files**
- Identifying zeroâ€‘length and â€œlowâ€‘valueâ€ files
- Performing safe cleanup (dryâ€‘run first, force required)

---

## ğŸ§© Requirements

- BusyBox / Synology DSM compatible (pure POSIX `sh`)
- Uses common tools: `awk`, `sort`, `stat`, `find`, `rm`, `mv`
- Place the repo on the same volume you are hashing

---

# ğŸ§­ Usage (Happy Path)

## 1) Start hashing

```bash
./launcher.sh
```

In the launcher: **Option 1** starts hashing in safe background mode.

Outputs:

- `hashes/hasher-YYYY-MM-DD.csv`  
- `logs/background.log`  
- Zeroâ€‘length candidates under `zero-length/`

---

## 2) Find duplicate folders (**run this first**)

```bash
# Launcher option 2
bin/find-duplicate-folders.sh --input hashes/hasher-YYYY-MM-DD.csv --mode plan
```

Produces:

- `logs/duplicate-folders-plan-*.txt` â€” recommended for big, immediate space recovery

**Why folders first?**
- Huge wins
- Removes redundant whole trees
- Cleans up sidecars
- Shrinks file-level duplicate review dramatically
- Lower risk and simpler rollback

---

## 3) Apply duplicateâ€‘folder plan

```bash
# Launcher option 6
bin/apply-folder-plan.sh --plan <planfile> --force
```

or:

```bash
bin/apply-folder-plan.sh --plan <planfile> --force --quarantine <dir>
```

---

## 4) Find duplicate files

```bash
# Launcher option 3
bin/find-duplicates.sh --input hashes/hasher-YYYY-MM-DD.csv
```

Outputs:

- `logs/YYYY-MM-DD-duplicate-hashes.txt`

---

## 5) Review duplicate files & build deletion plan

```bash
# Launcher option 4 (interactive)
bin/review-duplicates.sh --from-report logs/<report>.txt
```

Produces:

- `logs/review-dedupe-plan-*.txt`  
- Optionally diverts low-value groups into `var/low-value/`

New in v1.0.9:
- **A = add hash to exceptions list** (`local/exceptions-hashes.txt`)
- Safer numeric handling
- Backwardsâ€‘compatible CLI argument detection

---

## 6) Apply fileâ€‘level plan

```bash
# Launcher option 6 (autoâ€‘detects latest file plan)
bin/delete-duplicates.sh --from-plan <plan> --force
```

Supports:
- `--quarantine <dir>`
- `--apply-excludes`
- Multi-pass verify â†’ dry-run â†’ force

---

## 7) Zeroâ€‘length file cleanup

```bash
bin/delete-zero-length.sh <listfile> --verify-only
bin/delete-zero-length.sh <listfile>
bin/delete-zero-length.sh <listfile> --force
```

Respects:
- exclude rules
- CRLFâ€‘safe
- quarantine supported

---

## 8) Delete junk

```bash
# Launcher option 11
bin/delete-junk.sh --paths-file local/paths.txt --verify-only
```

Can optionally include or quarantine recycle contents.

---

## 9) Hash lookup (NEW)

```bash
# Launcher option 12
bin/hash-check.sh <sha256>
```

For locating exactlyâ€‘matching files by digest.

---

## 10) Stats & cron helper (NEW)

```bash
# Launcher option 13
```

Shows:

- How many hash runs
- Latest hash CSV
- Count of duplicate plans
- Latest plan file
- Cron templates for nightly hashing and weekly junk cleaning

---

## 11) Clean internal working files (NEW)

```bash
# Launcher option 14
```

Safely wipes everything inside:

```
var/
```

â€¦but **keeps hashes + logs** intact.  
Useful after several cycles to reduce noise.  
Safe to run during active hashing (does not affect hashing output).

---

# âš™ï¸ Configuration

We use a **default/local** overlay model:

```
default/hasher.conf
local/hasher.conf
local/paths.txt
local/excludes.txt
local/exceptions-hashes.txt   # new in 1.0.9
```

Key fields:

```ini
LOW_VALUE_THRESHOLD_BYTES=0
ZERO_APPLY_EXCLUDES=false
EXCLUDES_FILE=local/excludes.txt
QUARANTINE_DIR="/volume1/hasher/quarantine-$(date +%F)"
```

Precedence:

```
CLI flags > local/hasher.conf > default/hasher.conf > excludes.txt > built-ins
```

---

# ğŸ“‚ Structure

```
â”œâ”€â”€ bin/
â”‚   â”œâ”€â”€ hasher.sh
â”‚   â”œâ”€â”€ find-duplicate-folders.sh
â”‚   â”œâ”€â”€ apply-folder-plan.sh
â”‚   â”œâ”€â”€ find-duplicates.sh
â”‚   â”œâ”€â”€ review-duplicates.sh
â”‚   â”œâ”€â”€ delete-duplicates.sh
â”‚   â”œâ”€â”€ delete-zero-length.sh
â”‚   â”œâ”€â”€ delete-junk.sh
â”‚   â””â”€â”€ hash-check.sh
â”œâ”€â”€ default/
â”œâ”€â”€ local/
â”‚   â”œâ”€â”€ paths.txt
â”‚   â”œâ”€â”€ excludes.txt
â”‚   â””â”€â”€ exceptions-hashes.txt
â”œâ”€â”€ hashes/
â”œâ”€â”€ logs/
â”œâ”€â”€ var/
â”œâ”€â”€ zero-length/
â”œâ”€â”€ quarantine-YYYY-MM-DD/
â””â”€â”€ launcher.sh
```

---

# ğŸ›¡ï¸ Safety Model

- Everything is **verified again** before deletion
- Most scripts run **dryâ€‘run** by default
- All destructive steps require `--force`
- Quarantine-first recommended
- Robust CRLF handling
- Backwardsâ€‘compatible argument parsing

---

# ğŸ©º Troubleshooting

**Verify shows all files missing**  
â†’ Input list is CRLF. Fix with:
```bash
sed -i 's/
$//' <file>
```

**Slow file review UI**  
â†’ Run duplicateâ€‘folders first.

**Plans not applying**  
â†’ Ensure plan points to existing paths; reâ€‘run review after folder cleanup.

---

# ğŸ“œ License

GPLv3.

---

# ğŸ“š Related Reading

Facebook â€“ Silent Data Corruption  
https://engineering.fb.com/2021/02/23/data-infrastructure/silent-data-corruption/
